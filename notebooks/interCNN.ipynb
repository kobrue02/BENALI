{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "287b8aed-db85-41f3-8928-d40fdf8f39bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wandb in /opt/conda/lib/python3.12/site-packages (0.21.1)\n",
      "Requirement already satisfied: click!=8.0.0,>=7.1 in /opt/conda/lib/python3.12/site-packages (from wandb) (8.1.8)\n",
      "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /opt/conda/lib/python3.12/site-packages (from wandb) (3.1.44)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.12/site-packages (from wandb) (24.2)\n",
      "Requirement already satisfied: platformdirs in /opt/conda/lib/python3.12/site-packages (from wandb) (4.3.7)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<7,>=3.19.0 in /opt/conda/lib/python3.12/site-packages (from wandb) (5.29.3)\n",
      "Requirement already satisfied: pydantic<3 in /opt/conda/lib/python3.12/site-packages (from wandb) (2.11.3)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.12/site-packages (from wandb) (6.0.2)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in /opt/conda/lib/python3.12/site-packages (from wandb) (2.32.3)\n",
      "Requirement already satisfied: sentry-sdk>=2.0.0 in /opt/conda/lib/python3.12/site-packages (from wandb) (2.34.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.8 in /opt/conda/lib/python3.12/site-packages (from wandb) (4.13.2)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.12/site-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.12)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/conda/lib/python3.12/site-packages (from pydantic<3->wandb) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.1 in /opt/conda/lib/python3.12/site-packages (from pydantic<3->wandb) (2.33.1)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /opt/conda/lib/python3.12/site-packages (from pydantic<3->wandb) (0.4.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/conda/lib/python3.12/site-packages (from requests<3,>=2.0.0->wandb) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.12/site-packages (from requests<3,>=2.0.0->wandb) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.12/site-packages (from requests<3,>=2.0.0->wandb) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.12/site-packages (from requests<3,>=2.0.0->wandb) (2025.1.31)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /opt/conda/lib/python3.12/site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "566f30b1-6d79-44c3-9eea-af71f268aecf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers==4.54.1 in /opt/conda/lib/python3.12/site-packages (4.54.1)\n",
      "Requirement already satisfied: tokenizers==0.21.4 in /opt/conda/lib/python3.12/site-packages (0.21.4)\n",
      "Requirement already satisfied: sentencepiece==0.2.0 in /opt/conda/lib/python3.12/site-packages (0.2.0)\n",
      "Requirement already satisfied: tiktoken==0.9.0 in /opt/conda/lib/python3.12/site-packages (0.9.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.12/site-packages (from transformers==4.54.1) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /opt/conda/lib/python3.12/site-packages (from transformers==4.54.1) (0.34.4)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.12/site-packages (from transformers==4.54.1) (2.2.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.12/site-packages (from transformers==4.54.1) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.12/site-packages (from transformers==4.54.1) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.12/site-packages (from transformers==4.54.1) (2025.7.34)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.12/site-packages (from transformers==4.54.1) (2.32.3)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /opt/conda/lib/python3.12/site-packages (from transformers==4.54.1) (0.6.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.12/site-packages (from transformers==4.54.1) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers==4.54.1) (2025.3.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers==4.54.1) (4.13.2)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /opt/conda/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers==4.54.1) (1.1.7)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/conda/lib/python3.12/site-packages (from requests->transformers==4.54.1) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.12/site-packages (from requests->transformers==4.54.1) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.12/site-packages (from requests->transformers==4.54.1) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.12/site-packages (from requests->transformers==4.54.1) (2025.1.31)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install transformers==4.54.1 tokenizers==0.21.4 sentencepiece==0.2.0 tiktoken==0.9.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5313ecfe-93ef-4559-8ae5-ca6dde1c5a4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchvision in /opt/conda/lib/python3.12/site-packages (0.21.0+cu124)\n",
      "Collecting torchvision\n",
      "  Downloading torchvision-0.23.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.12/site-packages (from torchvision) (2.2.4)\n",
      "Collecting torch==2.8.0 (from torchvision)\n",
      "  Downloading torch-2.8.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (30 kB)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.12/site-packages (from torchvision) (11.1.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.12/site-packages (from torch==2.8.0->torchvision) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /opt/conda/lib/python3.12/site-packages (from torch==2.8.0->torchvision) (4.13.2)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.12/site-packages (from torch==2.8.0->torchvision) (78.1.0)\n",
      "Collecting sympy>=1.13.3 (from torch==2.8.0->torchvision)\n",
      "  Downloading sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.12/site-packages (from torch==2.8.0->torchvision) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.12/site-packages (from torch==2.8.0->torchvision) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.12/site-packages (from torch==2.8.0->torchvision) (2025.3.2)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.8.93 (from torch==2.8.0->torchvision)\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.8.90 (from torch==2.8.0->torchvision)\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.8.90 (from torch==2.8.0->torchvision)\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.10.2.21 (from torch==2.8.0->torchvision)\n",
      "  Downloading nvidia_cudnn_cu12-9.10.2.21-py3-none-manylinux_2_27_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-cublas-cu12==12.8.4.1 (from torch==2.8.0->torchvision)\n",
      "  Downloading nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cufft-cu12==11.3.3.83 (from torch==2.8.0->torchvision)\n",
      "  Downloading nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.9.90 (from torch==2.8.0->torchvision)\n",
      "  Downloading nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.7.3.90 (from torch==2.8.0->torchvision)\n",
      "  Downloading nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.5.8.93 (from torch==2.8.0->torchvision)\n",
      "  Downloading nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-cusparselt-cu12==0.7.1 (from torch==2.8.0->torchvision)\n",
      "  Downloading nvidia_cusparselt_cu12-0.7.1-py3-none-manylinux2014_x86_64.whl.metadata (7.0 kB)\n",
      "Collecting nvidia-nccl-cu12==2.27.3 (from torch==2.8.0->torchvision)\n",
      "  Downloading nvidia_nccl_cu12-2.27.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.0 kB)\n",
      "Collecting nvidia-nvtx-cu12==12.8.90 (from torch==2.8.0->torchvision)\n",
      "  Downloading nvidia_nvtx_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-nvjitlink-cu12==12.8.93 (from torch==2.8.0->torchvision)\n",
      "  Downloading nvidia_nvjitlink_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cufile-cu12==1.13.1.3 (from torch==2.8.0->torchvision)\n",
      "  Downloading nvidia_cufile_cu12-1.13.1.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting triton==3.4.0 (from torch==2.8.0->torchvision)\n",
      "  Downloading triton-3.4.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.12/site-packages (from sympy>=1.13.3->torch==2.8.0->torchvision) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.12/site-packages (from jinja2->torch==2.8.0->torchvision) (3.0.2)\n",
      "Downloading torchvision-0.23.0-cp312-cp312-manylinux_2_28_x86_64.whl (8.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.6/8.6 MB\u001b[0m \u001b[31m197.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading torch-2.8.0-cp312-cp312-manylinux_2_28_x86_64.whl (887.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m887.9/887.9 MB\u001b[0m \u001b[31m152.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl (594.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m594.3/594.3 MB\u001b[0m \u001b[31m163.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (10.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m192.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (88.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.0/88.0 MB\u001b[0m \u001b[31m161.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (954 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m954.8/954.8 kB\u001b[0m \u001b[31m375.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.10.2.21-py3-none-manylinux_2_27_x86_64.whl (706.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m706.8/706.8 MB\u001b[0m \u001b[31m146.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (193.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.1/193.1 MB\u001b[0m \u001b[31m222.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufile_cu12-1.13.1.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m270.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl (63.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.6/63.6 MB\u001b[0m \u001b[31m171.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl (267.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m267.5/267.5 MB\u001b[0m \u001b[31m170.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (288.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m288.2/288.2 MB\u001b[0m \u001b[31m162.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparselt_cu12-0.7.1-py3-none-manylinux2014_x86_64.whl (287.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m287.2/287.2 MB\u001b[0m \u001b[31m191.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nccl_cu12-2.27.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (322.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m322.4/322.4 MB\u001b[0m \u001b[31m158.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (39.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.3/39.3 MB\u001b[0m \u001b[31m191.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvtx_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89 kB)\n",
      "Downloading triton-3.4.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (155.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m155.6/155.6 MB\u001b[0m \u001b[31m160.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m256.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: nvidia-cusparselt-cu12, triton, sympy, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufile-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cufft-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch, torchvision\n",
      "  Attempting uninstall: nvidia-cusparselt-cu12\n",
      "    Found existing installation: nvidia-cusparselt-cu12 0.6.2\n",
      "    Uninstalling nvidia-cusparselt-cu12-0.6.2:\n",
      "      Successfully uninstalled nvidia-cusparselt-cu12-0.6.2\n",
      "  Attempting uninstall: triton\n",
      "    Found existing installation: triton 3.2.0\n",
      "    Uninstalling triton-3.2.0:\n",
      "      Successfully uninstalled triton-3.2.0\n",
      "  Attempting uninstall: sympy\n",
      "    Found existing installation: sympy 1.13.1\n",
      "    Uninstalling sympy-1.13.1:\n",
      "      Successfully uninstalled sympy-1.13.1\n",
      "  Attempting uninstall: nvidia-nvtx-cu12\n",
      "    Found existing installation: nvidia-nvtx-cu12 12.4.127\n",
      "    Uninstalling nvidia-nvtx-cu12-12.4.127:\n",
      "      Successfully uninstalled nvidia-nvtx-cu12-12.4.127\n",
      "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
      "    Found existing installation: nvidia-nvjitlink-cu12 12.4.127\n",
      "    Uninstalling nvidia-nvjitlink-cu12-12.4.127:\n",
      "      Successfully uninstalled nvidia-nvjitlink-cu12-12.4.127\n",
      "  Attempting uninstall: nvidia-nccl-cu12\n",
      "    Found existing installation: nvidia-nccl-cu12 2.21.5\n",
      "    Uninstalling nvidia-nccl-cu12-2.21.5:\n",
      "      Successfully uninstalled nvidia-nccl-cu12-2.21.5\n",
      "  Attempting uninstall: nvidia-curand-cu12\n",
      "    Found existing installation: nvidia-curand-cu12 10.3.5.147\n",
      "    Uninstalling nvidia-curand-cu12-10.3.5.147:\n",
      "      Successfully uninstalled nvidia-curand-cu12-10.3.5.147\n",
      "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
      "    Found existing installation: nvidia-cuda-runtime-cu12 12.4.127\n",
      "    Uninstalling nvidia-cuda-runtime-cu12-12.4.127:\n",
      "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.4.127\n",
      "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
      "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.4.127\n",
      "    Uninstalling nvidia-cuda-nvrtc-cu12-12.4.127:\n",
      "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.4.127\n",
      "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
      "    Found existing installation: nvidia-cuda-cupti-cu12 12.4.127\n",
      "    Uninstalling nvidia-cuda-cupti-cu12-12.4.127:\n",
      "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.4.127\n",
      "  Attempting uninstall: nvidia-cublas-cu12\n",
      "    Found existing installation: nvidia-cublas-cu12 12.4.5.8\n",
      "    Uninstalling nvidia-cublas-cu12-12.4.5.8:\n",
      "      Successfully uninstalled nvidia-cublas-cu12-12.4.5.8\n",
      "  Attempting uninstall: nvidia-cusparse-cu12\n",
      "    Found existing installation: nvidia-cusparse-cu12 12.3.1.170\n",
      "    Uninstalling nvidia-cusparse-cu12-12.3.1.170:\n",
      "      Successfully uninstalled nvidia-cusparse-cu12-12.3.1.170\n",
      "  Attempting uninstall: nvidia-cufft-cu12\n",
      "    Found existing installation: nvidia-cufft-cu12 11.2.1.3\n",
      "    Uninstalling nvidia-cufft-cu12-11.2.1.3:\n",
      "      Successfully uninstalled nvidia-cufft-cu12-11.2.1.3\n",
      "  Attempting uninstall: nvidia-cudnn-cu12\n",
      "    Found existing installation: nvidia-cudnn-cu12 9.1.0.70\n",
      "    Uninstalling nvidia-cudnn-cu12-9.1.0.70:\n",
      "      Successfully uninstalled nvidia-cudnn-cu12-9.1.0.70\n",
      "  Attempting uninstall: nvidia-cusolver-cu12\n",
      "    Found existing installation: nvidia-cusolver-cu12 11.6.1.9\n",
      "    Uninstalling nvidia-cusolver-cu12-11.6.1.9:\n",
      "      Successfully uninstalled nvidia-cusolver-cu12-11.6.1.9\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 2.6.0+cu124\n",
      "    Uninstalling torch-2.6.0+cu124:\n",
      "      Successfully uninstalled torch-2.6.0+cu124\n",
      "  Attempting uninstall: torchvision\n",
      "    Found existing installation: torchvision 0.21.0+cu124\n",
      "    Uninstalling torchvision-0.21.0+cu124:\n",
      "      Successfully uninstalled torchvision-0.21.0+cu124\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "torchaudio 2.6.0+cu124 requires torch==2.6.0, but you have torch 2.8.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed nvidia-cublas-cu12-12.8.4.1 nvidia-cuda-cupti-cu12-12.8.90 nvidia-cuda-nvrtc-cu12-12.8.93 nvidia-cuda-runtime-cu12-12.8.90 nvidia-cudnn-cu12-9.10.2.21 nvidia-cufft-cu12-11.3.3.83 nvidia-cufile-cu12-1.13.1.3 nvidia-curand-cu12-10.3.9.90 nvidia-cusolver-cu12-11.7.3.90 nvidia-cusparse-cu12-12.5.8.93 nvidia-cusparselt-cu12-0.7.1 nvidia-nccl-cu12-2.27.3 nvidia-nvjitlink-cu12-12.8.93 nvidia-nvtx-cu12-12.8.90 sympy-1.14.0 torch-2.8.0 torchvision-0.23.0 triton-3.4.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4486eccc-f320-4549-bb69-ca8d55549bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import wandb\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch import optim, nn\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "82d60136-343b-4176-b80e-ebd6eb4e1e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"nli_train_balanced_v2.csv\")\n",
    "val_data = pd.read_csv(\"nli_val.csv\")\n",
    "test_data = pd.read_csv(\"nli_test.csv\")\n",
    "\n",
    "# one-hot label encodings\n",
    "le = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b00d96ae-46ff-48dd-b9a5-da05cb5a4c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = list(set(train_data.l1.unique().tolist() + test_data.l1.unique().tolist() + val_data.l1.unique().tolist()))\n",
    "le.fit(labels)\n",
    "train_data['l1'] = le.transform(train_data['l1'])\n",
    "val_data['l1'] = le.transform(val_data['l1'])\n",
    "test_data['l1'] = le.transform(test_data['l1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4422d207-8e9f-4395-826d-4bf999d9454e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentenceData(Dataset):\n",
    "  \n",
    "    def __init__(self, df, remove_low_count=False, label_encoder=None):\n",
    "        self.df = df\n",
    "        if remove_low_count:\n",
    "            print(\"Removing:\")\n",
    "            print(label_encoder.inverse_transform(df['l1'].value_counts()[df['l1'].value_counts() <= 100].index))\n",
    "            self.df = self.df[self.df['l1'].map(self.df['l1'].value_counts()) >= 100]\n",
    "        self.sentences = df['sentence'].values.tolist()\n",
    "        self.labels = df['l1'].values.tolist()\n",
    "  \n",
    "    def __len__(self):\n",
    "        return len(self.sentences)\n",
    "  \n",
    "    def __getitem__(self, idx):\n",
    "        sentence = self.sentences[idx]\n",
    "        label = self.labels[idx]\n",
    "        return str(sentence), label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8b7350ba-f974-4fb6-be73-cc543633a0f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = SentenceData(train_data)\n",
    "val_data = SentenceData(val_data)\n",
    "test_data = SentenceData(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "09089876-d853-48ad-b135-ea3f5cca063d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "224776"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a9cb2390-0ed9-4b56-8517-c1d3b2665d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerFeatureExtractor(nn.Module):\n",
    "    \"\"\"\n",
    "    Wrapper to extract intermediate representations from a transformer model.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, hf_model_name, layer_indices=[-7, -6, -5, -4], freeze_transformer=True):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.transformer = AutoModel.from_pretrained(hf_model_name)\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(hf_model_name)\n",
    "        self.hidden_size = self.transformer.config.hidden_size\n",
    "        self.layer_indices = layer_indices\n",
    "        self.freeze_transformer = freeze_transformer\n",
    "        \n",
    "        if self.freeze_transformer:\n",
    "            for param in self.transformer.parameters():\n",
    "                param.requires_grad = False\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.tokenizer(x, return_tensors=\"pt\", truncation=True, padding=True, max_length=512).to(\"cuda\")\n",
    "        outputs = self.transformer(\n",
    "            input_ids=x[\"input_ids\"], \n",
    "            attention_mask=x[\"attention_mask\"],\n",
    "            output_hidden_states=True\n",
    "        )\n",
    "        \n",
    "        hidden_states = outputs.hidden_states\n",
    "        intermediate_reps = [hidden_states[idx] for idx in self.layer_indices]\n",
    "\n",
    "        return torch.cat(intermediate_reps, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "73377a6f-4e0e-420e-9645-0eee228e8eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN1DClassifier(nn.Module):\n",
    "    \"\"\"\n",
    "    1D CNN for sequence classification on (intermediate) transformer representations\n",
    "    \"\"\"\n",
    "    def __init__(self, input_dim, num_classes, num_filters=256, filter_sizes=[3, 4, 5, 6], dropout=0.4):\n",
    "        \n",
    "        super().__init__()\n",
    "        self.convs = nn.ModuleList([\n",
    "            nn.Conv1d(input_dim, num_filters, kernel_size=k)\n",
    "            for k in filter_sizes\n",
    "        ])\n",
    "    \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.linear = nn.Linear(len(filter_sizes) * num_filters, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # transpose input shape [batch_size, seq_len, input_dim]\n",
    "        # to [batch_size, input_dim, seq_len] for conv1d\n",
    "        x = x.transpose(1, 2)\n",
    "        x = [\n",
    "            torch.max(torch.relu(conv(x)), dim=2)[0] # conv + relu + pooling\n",
    "            for conv in self.convs\n",
    "        ]\n",
    "        x = torch.cat(x, dim=1)  # [batch_size, len(filter_sizes) * num_filters]\n",
    "        x = self.dropout(x)\n",
    "        return self.linear(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "52172485-70b3-41d6-b9f8-bdbcddeda0dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerCNN(nn.Module):    \n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        hf_model_name,\n",
    "        num_classes,\n",
    "        layer_indices=[-7, -6, -5, -4], \n",
    "        freeze_transformer=True,\n",
    "        cnn_config={}\n",
    "        ):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.tfe = TransformerFeatureExtractor(\n",
    "            hf_model_name, layer_indices, freeze_transformer\n",
    "        )\n",
    "        \n",
    "        # input dimension for CNN = hidden_size * num_layers\n",
    "        input_dim = self.tfe.hidden_size * len(self.tfe.layer_indices)\n",
    "    \n",
    "        self.cnn = CNN1DClassifier(\n",
    "            input_dim=input_dim,\n",
    "            num_classes=num_classes,\n",
    "            **cnn_config\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.tfe(x)\n",
    "        return self.cnn(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0878c2f2-12ea-4495-911c-6dce97676fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "from collections import defaultdict\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import precision_recall_fscore_support, classification_report\n",
    "from sklearn.model_selection import KFold\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import torch\n",
    "import warnings\n",
    "import uuid\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "def validate(clf, val_loader, criterion):\n",
    "    clf.eval()\n",
    "    val_loss = 0\n",
    "    val_acc = 0\n",
    "    val_samples = 0\n",
    "    with torch.no_grad():\n",
    "        for val_sents, val_labels in val_loader:\n",
    "            val_labels = torch.tensor(val_labels, device=\"cuda\")\n",
    "            val_outputs = clf(val_sents)\n",
    "            \n",
    "            val_loss += criterion(val_outputs, val_labels).item()\n",
    "            val_pred = torch.argmax(val_outputs, dim=1)\n",
    "            val_acc += torch.sum(val_pred == val_labels).item()\n",
    "            val_samples += val_labels.size(0)\n",
    "    \n",
    "    avg_val_loss = val_loss / len(val_loader)\n",
    "    avg_val_acc = val_acc / val_samples\n",
    "    \n",
    "    return avg_val_loss, avg_val_acc\n",
    "\n",
    "def train(clf, criterion, optimizer, train_loader, n_batches, epochs, run, log_freq, pbar):\n",
    "    clf.train()\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    for i, (sentences, labels) in enumerate(train_loader):\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        \n",
    "        labels = torch.tensor(labels, device=\"cuda\")\n",
    "        outputs = clf(sentences)\n",
    "        \n",
    "        loss = criterion(outputs, labels)\n",
    "        pred = torch.argmax(outputs, dim=1)\n",
    "        train_acc = torch.sum(pred == labels)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += train_acc.item()\n",
    "        \n",
    "        if i % log_freq == 0:\n",
    "            run.log({\"batch_loss\": loss, \"batch_train_acc\": train_acc / labels.size(0)})\n",
    "        pbar.update(1)\n",
    "    \n",
    "    avg_train_loss = epoch_loss / len(train_loader)\n",
    "    avg_train_acc = epoch_acc / len(train_loader.dataset)\n",
    "    \n",
    "    return avg_train_loss, avg_train_acc\n",
    "\n",
    "def training_loop(clf, criterion, optimizer, train_loader, n_batches, epochs, val_loader, run):\n",
    "    total_batches = len(train_loader) * epochs\n",
    "    pbar = tqdm(total=total_batches, desc='Training')\n",
    "    for e in range(epochs):\n",
    "        run.log({\"epoch\": e})\n",
    "        avg_train_loss, avg_train_acc = train(clf, criterion, optimizer, train_loader, n_batches, epochs, run, log_interval, pbar)\n",
    "        avg_val_loss, avg_val_acc = validate(clf, val_loader, criterion)\n",
    "        run.log({\n",
    "            \"epoch_train_loss\": avg_train_loss,\n",
    "            \"epoch_train_acc\": avg_train_acc,\n",
    "            \"epoch_val_loss\": avg_val_loss,\n",
    "            \"epoch_val_acc\": avg_val_acc\n",
    "        })\n",
    "        pbar.set_postfix({\n",
    "            'epoch': f'{e+1}/{epochs}',\n",
    "            'loss': f'{avg_train_loss:.4f}'\n",
    "        })\n",
    "    model_name = str(uuid.uuid4())\n",
    "    try:\n",
    "        torch.save(clf.state_dict(), f\"checkpoints/{model_name}.pt\")\n",
    "    except RuntimeError: pass\n",
    "\n",
    "def test_loop(clf, test_loader, le, run):\n",
    "    clf.eval()\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    target_names = [str(name) for name in le.classes_]\n",
    "    for i, (sentences, labels) in tqdm(enumerate(test_loader), total=len(test_loader)):\n",
    "        labels = torch.tensor(labels, device=\"cuda\")\n",
    "        outputs = clf(sentences)\n",
    "        preds = torch.argmax(outputs, dim=1)\n",
    "        y_true += labels.tolist()\n",
    "        y_pred += preds.tolist()\n",
    "    \n",
    "    report = classification_report(\n",
    "            y_true,\n",
    "            y_pred,\n",
    "            target_names=target_names,\n",
    "            labels=list(range(len(target_names)))\n",
    "    )\n",
    "    ma_p, ma_r, ma_f1, _ = precision_recall_fscore_support(y_true, y_pred, average='macro')\n",
    "    mi_p, mi_r, mi_f1, _ = precision_recall_fscore_support(y_true, y_pred, average='micro')\n",
    "    w_p, w_r, w_f1, _ = precision_recall_fscore_support(y_true, y_pred, average='weighted')\n",
    "    run.log({\n",
    "        \"test_macro_precision\": ma_p,\n",
    "        \"test_macro_recall\": ma_r,\n",
    "        \"test_macro_f1\": ma_f1,\n",
    "        \"test_micro_precision\": mi_p,\n",
    "        \"test_micro_recall\": mi_r,\n",
    "        \"test_micro_f1\": mi_f1,\n",
    "        \"test_weighted_precision\": w_p,\n",
    "        \"test_weighted_recall\": w_r,\n",
    "        \"test_weighted_f1\": w_f1\n",
    "    })\n",
    "    return report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4e139a2e-2130-403f-8a3a-696315989b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_fold(clf, test_loader, le):\n",
    "    \"\"\"Test a single fold and return metrics\"\"\"\n",
    "    clf.eval()\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    target_names = [str(name) for name in le.classes_]\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for sentences, labels in test_loader:\n",
    "            labels = torch.tensor(labels, device=\"cuda\")\n",
    "            outputs = clf(sentences)\n",
    "            preds = torch.argmax(outputs, dim=1)\n",
    "            y_true += labels.tolist()\n",
    "            y_pred += preds.tolist()\n",
    "    \n",
    "    # macro/micro/weighted metrics\n",
    "    ma_p, ma_r, ma_f1, _ = precision_recall_fscore_support(y_true, y_pred, average='macro')\n",
    "    mi_p, mi_r, mi_f1, _ = precision_recall_fscore_support(y_true, y_pred, average='micro')\n",
    "    w_p, w_r, w_f1, _ = precision_recall_fscore_support(y_true, y_pred, average='weighted')\n",
    "    \n",
    "    metrics = {\n",
    "        \"macro_precision\": ma_p,\n",
    "        \"macro_recall\": ma_r,\n",
    "        \"macro_f1\": ma_f1,\n",
    "        \"micro_precision\": mi_p,\n",
    "        \"micro_recall\": mi_r,\n",
    "        \"micro_f1\": mi_f1,\n",
    "        \"weighted_precision\": w_p,\n",
    "        \"weighted_recall\": w_r,\n",
    "        \"weighted_f1\": w_f1\n",
    "    }\n",
    "    \n",
    "    report = classification_report(\n",
    "        y_true,\n",
    "        y_pred,\n",
    "        target_names=target_names,\n",
    "        labels=list(range(len(target_names)))\n",
    "    )\n",
    "    \n",
    "    return metrics, report\n",
    "\n",
    "def cross_validation(clf_class, dataset, le, criterion_class, optimizer_class, \n",
    "                    n_splits=5, epochs=10, batch_size=32, lr=1e-3, \n",
    "                    log_interval=100, stratified=True, run=None, **model_kwargs):\n",
    "    \"\"\"\n",
    "    Perform k-fold cross validation\n",
    "    \n",
    "    Args:\n",
    "        clf_class: The model class (not instantiated)\n",
    "        dataset: Your full dataset (torch Dataset)\n",
    "        le: Label encoder\n",
    "        criterion_class: Loss function class\n",
    "        optimizer_class: Optimizer class (e.g., torch.optim.Adam)\n",
    "        n_splits: Number of folds\n",
    "        epochs: Number of epochs per fold\n",
    "        batch_size: Batch size\n",
    "        lr: Learning rate\n",
    "        log_interval: Logging frequency\n",
    "        stratified: Whether to use stratified k-fold\n",
    "        run: Experiment tracking object (wandb, etc.)\n",
    "        **model_kwargs: Arguments to pass to model constructor\n",
    "    \n",
    "    Returns:\n",
    "        dict: Cross-validation results\n",
    "    \"\"\"\n",
    "\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    if stratified:\n",
    "        all_labels = [dataset[i][1] for i in range(len(dataset))]\n",
    "        splits = list(kf.split(range(len(dataset)), all_labels))\n",
    "    else:\n",
    "        splits = list(kf.split(range(len(dataset))))\n",
    "    \n",
    "    fold_results = []\n",
    "    all_metrics = defaultdict(list)\n",
    "    \n",
    "    for fold, (train_val_idx, test_idx) in enumerate(splits):\n",
    "\n",
    "        val_size = len(train_val_idx) // 5  # 20% for validation\n",
    "        train_idx = train_val_idx[:-val_size]\n",
    "        val_idx = train_val_idx[-val_size:]\n",
    "        \n",
    "        train_loader = DataLoader(Subset(dataset, train_idx), batch_size=batch_size, shuffle=True)\n",
    "        val_loader = DataLoader(Subset(dataset, val_idx), batch_size=batch_size, shuffle=False)\n",
    "        test_loader = DataLoader(Subset(dataset, test_idx), batch_size=batch_size, shuffle=False)\n",
    "        \n",
    "        clf = clf_class(**model_kwargs).cuda()\n",
    "        criterion = criterion_class()\n",
    "        optimizer = optimizer_class(clf.parameters(), lr=lr)\n",
    "\n",
    "        # Train the model\n",
    "        final_val_loss, final_val_acc = training_loop(\n",
    "            clf, criterion, optimizer, train_loader, epochs, \n",
    "            val_loader, fold_run, log_interval\n",
    "        )\n",
    "        fold_metrics, fold_report = test_fold(clf, test_loader, le)\n",
    "        fold_result = {\n",
    "            'fold': fold + 1,\n",
    "            'final_val_loss': final_val_loss,\n",
    "            'final_val_acc': final_val_acc,\n",
    "            'test_metrics': fold_metrics,\n",
    "            'classification_report': fold_report\n",
    "        }\n",
    "        fold_results.append(fold_result)\n",
    "        \n",
    "        # accumulate metrics\n",
    "        for metric_name, metric_value in fold_metrics.items():\n",
    "            all_metrics[metric_name].append(metric_value)\n",
    "        \n",
    "        # log fold results\n",
    "        if run is not None:\n",
    "            fold_log = {f\"fold_{fold+1}_{k}\": v for k, v in fold_metrics.items()}\n",
    "            fold_log[f\"fold_{fold+1}_val_loss\"] = final_val_loss\n",
    "            fold_log[f\"fold_{fold+1}_val_acc\"] = final_val_acc\n",
    "            run.log(fold_log)\n",
    "    \n",
    "    # overall statistics\n",
    "    cv_results = {}\n",
    "    for metric_name, values in all_metrics.items():\n",
    "        cv_results[f\"{metric_name}_mean\"] = np.mean(values)\n",
    "        cv_results[f\"{metric_name}_std\"] = np.std(values)\n",
    "    \n",
    "    if run is not None:\n",
    "        cv_log = {f\"cv_{k}\": v for k, v in cv_results.items()}\n",
    "        run.log(cv_log)\n",
    "    \n",
    "    return {\n",
    "        'fold_results': fold_results,\n",
    "        'cv_metrics': cv_results,\n",
    "        'mean_macro_f1': cv_results['macro_f1_mean'],\n",
    "        'std_macro_f1': cv_results['macro_f1_std']\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "045a3bb3-a849-4361-aea1-f2f4ab163e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Subset\n",
    "from torch.optim import AdamW\n",
    "from torch.nn import CrossEntropyLoss\n",
    "\n",
    "n_classes = len(le.classes_)\n",
    "n_layers = 1\n",
    "batch_size = 32\n",
    "lr = 1e-2\n",
    "epochs = 10\n",
    "\n",
    "\n",
    "embedding_model=\"KonradBRG/benali\"\n",
    "\n",
    "clf = TransformerCNN(\n",
    "    embedding_model,\n",
    "    n_classes,\n",
    "    layer_indices=[-5], \n",
    "    freeze_transformer=True,\n",
    "    cnn_config={\n",
    "        \"num_filters\": 128,\n",
    "        \"dropout\": 0.5\n",
    "    }).to('cuda')\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size, num_workers=2, shuffle=True, pin_memory=True)\n",
    "val_loader = DataLoader(val_data, batch_size=batch_size, num_workers=2, shuffle=True, pin_memory=True)\n",
    "test_loader = DataLoader(test_data, batch_size=batch_size)\n",
    "\n",
    "# wandb\n",
    "args = {\n",
    "    \"entity\": \"konrad-brg-university-of-t-bingen\",\n",
    "    \"project\": \"BENALI\",\n",
    "    \"config\": {\n",
    "        \"learning_rate\": lr,\n",
    "        \"architecture\": \"BENALI+CNN\",\n",
    "        \"dataset\": \"dataset_clean.csv\",\n",
    "        \"epochs\": epochs,\n",
    "        \"log_interval\": 50,\n",
    "        \"n_batches\": len(train_loader),\n",
    "        \"criterion\": \"CrossEntropyLoss\"\n",
    "    },\n",
    "}\n",
    "\n",
    "train_config = {\n",
    "    \"clf\": clf,\n",
    "    \"optimizer\": AdamW(clf.parameters(), lr=lr),\n",
    "    \"criterion\": CrossEntropyLoss(),\n",
    "    \"train_loader\": train_loader,\n",
    "    \"val_loader\": val_loader,\n",
    "    \"n_batches\": len(train_loader),\n",
    "    \"epochs\": epochs,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0fc905e2-5d9f-4634-be08-1c74cc756385",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Failed to detect the name of this notebook. You can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: TOKENIZERS_PARALLELISM=true\n",
      "env: PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mkonrad-brg\u001b[0m (\u001b[33mkonrad-brg-university-of-t-bingen\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "creating run (0.5s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.21.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/jovyan/work/wandb/run-20250809_091841-ai93iu04</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/konrad-brg-university-of-t-bingen/BENALI/runs/ai93iu04' target=\"_blank\">rare-night-113</a></strong> to <a href='https://wandb.ai/konrad-brg-university-of-t-bingen/BENALI' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/konrad-brg-university-of-t-bingen/BENALI' target=\"_blank\">https://wandb.ai/konrad-brg-university-of-t-bingen/BENALI</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/konrad-brg-university-of-t-bingen/BENALI/runs/ai93iu04' target=\"_blank\">https://wandb.ai/konrad-brg-university-of-t-bingen/BENALI/runs/ai93iu04</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23b4146659c9461e9449539d42f90e26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/355300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05bfcdc14b504b5ba429d64f7ed1befe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7025 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_696/1531112262.py\", line 11, in <module>\n",
      "    cv_results = cross_validation(\n",
      "                 ^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_696/4060361331.py\", line 87, in cross_validation\n",
      "    clf = clf_class(**model_kwargs).cuda()\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: TransformerCNN.__init__() got an unexpected keyword argument 'num_workers'\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>batch_loss</td><td>▃▇▅▁▄▄▅▂▃▅▃▅▂▄▅▄▇▃▄▄▅▅▅▄▃▅▃▅▅▅▅▇▄▅▅▄█▅▅▅</td></tr><tr><td>batch_train_acc</td><td>▆▅▃▇█▆█▇▃█▆▃▂█▂▃▁▃▆▅▃▅▂▂▅▇▁▃▇▁▃▃▂▃▁▂▃▇▃▅</td></tr><tr><td>epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>epoch_train_acc</td><td>█▅▄▃▂▂▂▂▁▁</td></tr><tr><td>epoch_train_loss</td><td>▁▅▆▇█▇▇▇██</td></tr><tr><td>epoch_val_acc</td><td>▁█▂▆▆▇▇▇▆▃</td></tr><tr><td>epoch_val_loss</td><td>█▁▄▄▃▁▃▁▃▄</td></tr><tr><td>test_macro_f1</td><td>▁</td></tr><tr><td>test_macro_precision</td><td>▁</td></tr><tr><td>test_macro_recall</td><td>▁</td></tr><tr><td>test_micro_f1</td><td>▁</td></tr><tr><td>test_micro_precision</td><td>▁</td></tr><tr><td>test_micro_recall</td><td>▁</td></tr><tr><td>test_weighted_f1</td><td>▁</td></tr><tr><td>test_weighted_precision</td><td>▁</td></tr><tr><td>test_weighted_recall</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>batch_loss</td><td>4.04294</td></tr><tr><td>batch_train_acc</td><td>0.09375</td></tr><tr><td>epoch</td><td>9</td></tr><tr><td>epoch_train_acc</td><td>0.08374</td></tr><tr><td>epoch_train_loss</td><td>4.27414</td></tr><tr><td>epoch_val_acc</td><td>0.09412</td></tr><tr><td>epoch_val_loss</td><td>4.16696</td></tr><tr><td>test_macro_f1</td><td>0.01748</td></tr><tr><td>test_macro_precision</td><td>0.02414</td></tr><tr><td>test_macro_recall</td><td>0.02399</td></tr><tr><td>test_micro_f1</td><td>0.09449</td></tr><tr><td>test_micro_precision</td><td>0.09449</td></tr><tr><td>test_micro_recall</td><td>0.09449</td></tr><tr><td>test_weighted_f1</td><td>0.04346</td></tr><tr><td>test_weighted_precision</td><td>0.0541</td></tr><tr><td>test_weighted_recall</td><td>0.09449</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">rare-night-113</strong> at: <a href='https://wandb.ai/konrad-brg-university-of-t-bingen/BENALI/runs/ai93iu04' target=\"_blank\">https://wandb.ai/konrad-brg-university-of-t-bingen/BENALI/runs/ai93iu04</a><br> View project at: <a href='https://wandb.ai/konrad-brg-university-of-t-bingen/BENALI' target=\"_blank\">https://wandb.ai/konrad-brg-university-of-t-bingen/BENALI</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250809_091841-ai93iu04/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "TypeError",
     "evalue": "TransformerCNN.__init__() got an unexpected keyword argument 'num_workers'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 11\u001b[39m\n\u001b[32m      9\u001b[39m     training_loop(**train_config)\n\u001b[32m     10\u001b[39m     report = test_loop(clf, test_loader, le, run)\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m     cv_results = \u001b[43mcross_validation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m        \u001b[49m\u001b[43mclf_class\u001b[49m\u001b[43m=\u001b[49m\u001b[43mTransformerCNN\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m=\u001b[49m\u001b[43mConcatDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_data\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[43m        \u001b[49m\u001b[43mle\u001b[49m\u001b[43m=\u001b[49m\u001b[43mle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcriterion_class\u001b[49m\u001b[43m=\u001b[49m\u001b[43mCrossEntropyLoss\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[43m        \u001b[49m\u001b[43moptimizer_class\u001b[49m\u001b[43m=\u001b[49m\u001b[43mAdamW\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[43m        \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     20\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     21\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlog_interval\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m50\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     22\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstratified\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     23\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrun\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     24\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnum_workers\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     25\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpin_memory\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     26\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m     27\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43membedding_model\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mKonradBRG/benali\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     28\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mn_classes\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mle\u001b[49m\u001b[43m.\u001b[49m\u001b[43mclasses_\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     29\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlayer_indices\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m3\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     30\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfreeze_transformer\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     31\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcnn_config\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m     32\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mnum_filters\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m256\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     33\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdropout\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0.3\u001b[39;49m\n\u001b[32m     34\u001b[39m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\n\u001b[32m     35\u001b[39m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Your TransformerCNN parameters\u001b[39;49;00m\n\u001b[32m     36\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     37\u001b[39m     run.finish()\n\u001b[32m     38\u001b[39m \u001b[38;5;28mprint\u001b[39m(report)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 87\u001b[39m, in \u001b[36mcross_validation\u001b[39m\u001b[34m(clf_class, dataset, le, criterion_class, optimizer_class, n_splits, epochs, batch_size, lr, log_interval, stratified, run, **model_kwargs)\u001b[39m\n\u001b[32m     84\u001b[39m val_loader = DataLoader(Subset(dataset, val_idx), batch_size=batch_size, shuffle=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m     85\u001b[39m test_loader = DataLoader(Subset(dataset, test_idx), batch_size=batch_size, shuffle=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m---> \u001b[39m\u001b[32m87\u001b[39m clf = \u001b[43mclf_class\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m)\u001b[49m.cuda()\n\u001b[32m     88\u001b[39m criterion = criterion_class()\n\u001b[32m     89\u001b[39m optimizer = optimizer_class(clf.parameters(), lr=lr)\n",
      "\u001b[31mTypeError\u001b[39m: TransformerCNN.__init__() got an unexpected keyword argument 'num_workers'"
     ]
    }
   ],
   "source": [
    "%env TOKENIZERS_PARALLELISM=true\n",
    "%env PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True\n",
    "from torch.utils.data import ConcatDataset\n",
    "\n",
    "log_interval = args[\"config\"][\"log_interval\"]\n",
    "with wandb.init(**args) as run:\n",
    "    run.watch(clf, log_freq=10)\n",
    "    train_config.update({\"run\": run})\n",
    "    training_loop(**train_config)\n",
    "    report = test_loop(clf, test_loader, le, run)\n",
    "    cv_results = cross_validation(\n",
    "        clf_class=TransformerCNN,\n",
    "        dataset=ConcatDataset([train_data, val_data, test_data]),\n",
    "        le=le,\n",
    "        criterion_class=CrossEntropyLoss,\n",
    "        optimizer_class=AdamW,\n",
    "        n_splits=5,\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        lr=lr,\n",
    "        log_interval=50,\n",
    "        stratified=True,\n",
    "        run=run,\n",
    "        num_workers=2,\n",
    "        pin_memory=True,\n",
    "        **{\n",
    "            \"embedding_model\": \"KonradBRG/benali\",\n",
    "            \"n_classes\": len(le.classes_),\n",
    "            \"layer_indices\": [-5, -4, -3], \n",
    "            \"freeze_transformer\": True,\n",
    "            \"cnn_config\": {\n",
    "                \"num_filters\": 256,\n",
    "                \"dropout\": 0.3\n",
    "            }\n",
    "        }  # Your TransformerCNN parameters\n",
    "    )\n",
    "    run.finish()\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c60c55e-93cb-4f27-b300-e1991505f861",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb5c19e-3d8c-4c6a-83a5-8c7af9c1bf61",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
